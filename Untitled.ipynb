{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c72774e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                                               Text    Category\n",
      "0   1  Abstract: Wish up music want go prove happy. V...  Scientific\n",
      "1   2  This agreement is made between Grimes, Kaufman...       Legal\n",
      "2   3  I recently purchased land and it exceeded my e...  E-commerce\n",
      "3   4  This agreement is made between Brown PLC and V...       Legal\n",
      "4   5  I recently purchased wrong and it was disappoi...  E-commerce\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   ID        3000 non-null   int64 \n",
      " 1   Text      3000 non-null   object\n",
      " 2   Category  3000 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 70.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Document_Classifier_Dataset.csv(2).csv')\n",
    "print(df.head())\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb29f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abhis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Tokenize and clean\n",
    "df['cleaned_text'] = df['Text'].apply(\n",
    "    lambda x: ' '.join(\n",
    "        [word for word in x.split() if word.lower() not in stop_words]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['cleaned_text'])\n",
    "y = df['Category']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d2a058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 1801)\n",
      "(3000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fff75038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 1801) (600, 1801)\n",
      "(2400,) (600,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "752f2bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Blog       0.98      1.00      0.99       118\n",
      "  E-commerce       1.00      1.00      1.00       119\n",
      "       Legal       1.00      1.00      1.00       131\n",
      "        News       1.00      0.98      0.99       131\n",
      "  Scientific       1.00      1.00      1.00       101\n",
      "\n",
      "    accuracy                           0.99       600\n",
      "   macro avg       1.00      1.00      1.00       600\n",
      "weighted avg       1.00      0.99      1.00       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "562c19db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Blog' 'E-commerce' 'Legal' 'News' 'Scientific']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Convert labels to integers\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Check unique classes\n",
    "print(\"Classes:\", label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0acb2ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2400, 100)\n",
      "Test data shape: (600, 100)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tokenizer setup\n",
    "tokenizer = Tokenizer(num_words=10000)  # Keep top 10,000 words\n",
    "tokenizer.fit_on_texts(df['cleaned_text'])  # Fit tokenizer on the cleaned text\n",
    "\n",
    "# Split the cleaned text into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    df['cleaned_text'], df['Category'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_text)\n",
    "\n",
    "# Pad sequences to ensure consistent input length\n",
    "max_len = 100  # Define max sequence length\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
    "\n",
    "print(\"Training data shape:\", X_train_padded.shape)\n",
    "print(\"Test data shape:\", X_test_padded.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91286992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 140ms/step - accuracy: 0.1867 - loss: 1.6106 - val_accuracy: 0.1958 - val_loss: 1.6070\n",
      "Epoch 2/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 122ms/step - accuracy: 0.2108 - loss: 1.6104 - val_accuracy: 0.2375 - val_loss: 1.6080\n",
      "Epoch 3/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 144ms/step - accuracy: 0.2092 - loss: 1.6087 - val_accuracy: 0.1958 - val_loss: 1.6104\n",
      "Epoch 4/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 167ms/step - accuracy: 0.2185 - loss: 1.6082 - val_accuracy: 0.1896 - val_loss: 1.6121\n",
      "Epoch 5/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 183ms/step - accuracy: 0.1891 - loss: 1.6089 - val_accuracy: 0.2375 - val_loss: 1.6121\n",
      "Epoch 6/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 139ms/step - accuracy: 0.1931 - loss: 1.6075 - val_accuracy: 0.2375 - val_loss: 1.6094\n",
      "Epoch 7/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 120ms/step - accuracy: 0.2221 - loss: 1.6068 - val_accuracy: 0.2375 - val_loss: 1.6114\n",
      "Epoch 8/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 122ms/step - accuracy: 0.1855 - loss: 1.6096 - val_accuracy: 0.1958 - val_loss: 1.6148\n",
      "Epoch 9/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 134ms/step - accuracy: 0.2170 - loss: 1.6076 - val_accuracy: 0.1958 - val_loss: 1.6126\n",
      "Epoch 10/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 139ms/step - accuracy: 0.2180 - loss: 1.6083 - val_accuracy: 0.1667 - val_loss: 1.6118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e6b2649910>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Create a simple LSTM model\n",
    "model_dl = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=128),  # No need for `input_length`\n",
    "    LSTM(128, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_dl.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_dl.fit(X_train_padded, y_train_encoded, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f60d14ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       118\n",
      "           1       0.20      1.00      0.33       119\n",
      "           2       0.00      0.00      0.00       131\n",
      "           3       0.00      0.00      0.00       131\n",
      "           4       0.00      0.00      0.00       101\n",
      "\n",
      "    accuracy                           0.20       600\n",
      "   macro avg       0.04      0.20      0.07       600\n",
      "weighted avg       0.04      0.20      0.07       600\n",
      "\n",
      "Accuracy: 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model_dl.predict(X_test_padded)\n",
    "y_pred_classes = y_pred.argmax(axis=1)  # Convert probabilities to class indices\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_classes))\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_classes)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27f043e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras in c:\\users\\abhis\\anaconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from scikeras) (3.3.3)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from scikeras) (1.6.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (1.23.5)\n",
      "Requirement already satisfied: rich in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.3.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikeras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaf1afe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version: 1.6.1\n",
      "scikeras version: 0.13.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import scikeras\n",
    "\n",
    "print(\"scikit-learn version:\", sklearn.__version__)\n",
    "print(\"scikeras version:\", scikeras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71e9c004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\abhis\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: scikeras in c:\\users\\abhis\\anaconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from scikeras) (3.3.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (2.1.0)\n",
      "Requirement already satisfied: rich in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn scikeras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "888baaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\abhis\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a919d545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.0\n",
      "  Using cached scikit-learn-1.0.tar.gz (7.8 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [35 lines of output]\n",
      "  Partial import of sklearn during the build process.\n",
      "  <string>:128: DeprecationWarning:\n",
      "  \n",
      "    `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n",
      "    of the deprecation of `distutils` itself. It will be removed for\n",
      "    Python >= 3.12. For older Python versions it will remain present.\n",
      "    It is recommended to use `setuptools < 60.0` for those Python versions.\n",
      "    For more details, see:\n",
      "      https://numpy.org/devdocs/reference/distutils_status_migration.html\n",
      "  \n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "      main()\n",
      "    File \"C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 149, in prepare_metadata_for_build_wheel\n",
      "      return hook(metadata_directory, config_settings)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\abhis\\AppData\\Local\\Temp\\pip-build-env-xbhig2l7\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 377, in prepare_metadata_for_build_wheel\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\abhis\\AppData\\Local\\Temp\\pip-build-env-xbhig2l7\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 522, in run_setup\n",
      "      super().run_setup(setup_script=setup_script)\n",
      "    File \"C:\\Users\\abhis\\AppData\\Local\\Temp\\pip-build-env-xbhig2l7\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 320, in run_setup\n",
      "      exec(code, locals())\n",
      "    File \"<string>\", line 319, in <module>\n",
      "    File \"<string>\", line 311, in setup_package\n",
      "    File \"C:\\Users\\abhis\\AppData\\Local\\Temp\\pip-build-env-xbhig2l7\\overlay\\Lib\\site-packages\\numpy\\distutils\\core.py\", line 24, in <module>\n",
      "      from numpy.distutils.command import config, config_compiler, \\\n",
      "    File \"C:\\Users\\abhis\\AppData\\Local\\Temp\\pip-build-env-xbhig2l7\\overlay\\Lib\\site-packages\\numpy\\distutils\\command\\config.py\", line 19, in <module>\n",
      "      from numpy.distutils.mingw32ccompiler import generate_manifest\n",
      "    File \"C:\\Users\\abhis\\AppData\\Local\\Temp\\pip-build-env-xbhig2l7\\overlay\\Lib\\site-packages\\numpy\\distutils\\mingw32ccompiler.py\", line 28, in <module>\n",
      "      from distutils.msvccompiler import get_build_version as get_build_msvc_version\n",
      "  ModuleNotFoundError: No module named 'distutils.msvccompiler'\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn==1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5362fc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Obtaining dependency information for optuna from https://files.pythonhosted.org/packages/e8/30/35111dae435c640694d616a611b7ff6b2482cfd977f8f572ff960a321d66/optuna-4.1.0-py3-none-any.whl.metadata\n",
      "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Obtaining dependency information for alembic>=1.5.0 from https://files.pythonhosted.org/packages/cb/06/8b505aea3d77021b18dcbd8133aa1418f1a1e37e432a465b14c46b2c0eaa/alembic-1.14.0-py3-none-any.whl.metadata\n",
      "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Obtaining dependency information for colorlog from https://files.pythonhosted.org/packages/e3/51/9b208e85196941db2f0654ad0357ca6388ab3ed67efdbfc799f35d1f83aa/colorlog-6.9.0-py3-none-any.whl.metadata\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from optuna) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from optuna) (23.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from optuna) (1.4.39)\n",
      "Requirement already satisfied: tqdm in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from optuna) (6.0)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Obtaining dependency information for Mako from https://files.pythonhosted.org/packages/1e/bf/7a6a36ce2e4cafdfb202752be68850e22607fccd692847c45c1ae3c17ba6/Mako-1.3.8-py3-none-any.whl.metadata\n",
      "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
      "   ---------------------------------------- 0.0/364.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 364.4/364.4 kB 11.4 MB/s eta 0:00:00\n",
      "Downloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
      "   ---------------------------------------- 0.0/233.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 233.5/233.5 kB 14.0 MB/s eta 0:00:00\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.6/78.6 kB ? eta 0:00:00\n",
      "Installing collected packages: Mako, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.3.8 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51e90427",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:58:49,354] A new study created in memory with name: no-name-88d68a0a-d61f-42e2-99ac-31fbe8c04352\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 22 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001E6C6B3DD00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:59:10,107] Trial 0 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 85, 'dropout_rate': 0.3822879744632731}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 23 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001E6CA40A160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:59:31,557] Trial 1 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 230, 'dropout_rate': 0.3562513972690338}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 12:59:53,860] Trial 2 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 219, 'dropout_rate': 0.5996226607757678}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:00:18,648] Trial 3 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 205, 'dropout_rate': 0.6903126157441748}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:00:38,654] Trial 4 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 183, 'dropout_rate': 0.67078831936865}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:00:59,534] Trial 5 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 55, 'dropout_rate': 0.300226729681863}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:01:19,745] Trial 6 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 107, 'dropout_rate': 0.3039122537862023}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:01:40,583] Trial 7 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 256, 'dropout_rate': 0.6881949008445141}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:02:00,362] Trial 8 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 77, 'dropout_rate': 0.5405604476039856}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:02:21,483] Trial 9 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 206, 'dropout_rate': 0.49529384088629574}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:02:41,536] Trial 10 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 131, 'dropout_rate': 0.426069973230345}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:03:01,002] Trial 11 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 150, 'dropout_rate': 0.38519568601924575}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:03:20,991] Trial 12 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 103, 'dropout_rate': 0.38881460928915124}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:03:42,105] Trial 13 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 256, 'dropout_rate': 0.44772915992380385}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:04:02,705] Trial 14 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 172, 'dropout_rate': 0.3551134014604914}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:04:22,918] Trial 15 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 125, 'dropout_rate': 0.476857663146567}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:04:44,614] Trial 16 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 77, 'dropout_rate': 0.3447940266229477}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:05:06,832] Trial 17 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 162, 'dropout_rate': 0.5586372718907102}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:05:29,392] Trial 18 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 230, 'dropout_rate': 0.4195783813155134}. Best is trial 0 with value: -0.3333333333333333.\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:05:51,999] Trial 19 finished with value: -0.3333333333333333 and parameters: {'lstm_units': 54, 'dropout_rate': 0.347801776280862}. Best is trial 0 with value: -0.3333333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'lstm_units': 85, 'dropout_rate': 0.3822879744632731}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Define your model\n",
    "def create_model(X_train_padded, lstm_units=50, dropout_rate=0.5):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Set input shape based on the padded data shape\n",
    "    input_shape = (X_train_padded.shape[1], 1)  # Time steps and 1 feature (word embedding)\n",
    "    \n",
    "    model.add(LSTM(lstm_units, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(lstm_units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Change to appropriate activation and units for your task\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Example preprocessing of text data\n",
    "X_train = [\"Your\", \"data\", \"here\"]\n",
    "y_train = [\"your\", \"labels\", \"here\"]\n",
    "\n",
    "# Convert labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_padded = pad_sequences(X_train_sequences, padding='post')\n",
    "\n",
    "# Custom classifier wrapper\n",
    "class KerasWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y, epochs=10, batch_size=32, verbose=0)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.model.predict(X) > 0.5).astype(int)\n",
    "\n",
    "# Objective function for Optuna\n",
    "def objective(trial):\n",
    "    lstm_units = trial.suggest_int('lstm_units', 50, 256)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.3, 0.7)\n",
    "\n",
    "    # Create model\n",
    "    model = create_model(X_train_padded, lstm_units=lstm_units, dropout_rate=dropout_rate)\n",
    "    \n",
    "    # Use custom wrapper\n",
    "    model_wrapper = KerasWrapper(model)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    score = cross_val_score(model_wrapper, X_train_padded, y_train_encoded, cv=3)\n",
    "    \n",
    "    # Return the negative mean score (Optuna minimizes the objective)\n",
    "    return -score.mean()\n",
    "\n",
    "# Create a study for optimization\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", study.best_params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8f53e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
